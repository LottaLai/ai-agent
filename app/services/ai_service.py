import json
import logging
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional

from google import genai
from google.genai import types

from app.ai.builders.prompt_builder import SystemPromptBuilder
from app.ai.config.prompt_config import PromptConfig
from app.constants.enums import MessageRole, PromptType
from app.models.data_models import ChatMessage
from app.models.user_session import UserSession
from app.utils.exceptions import AIServiceError
from app.utils.formatters import ResponseFormatter
from config.setting import AISettings

logger = logging.getLogger(__name__)


class AIServiceInterface(ABC):
    """AI æœå‹™ä»‹é¢"""

    @abstractmethod
    async def generate_response(self, messages: List[ChatMessage]) -> str:
        """ç”Ÿæˆ AI å›æ‡‰"""
        pass

    @abstractmethod
    async def analyze_user_intent(
        self, user_input: str, session_history: dict, context: dict
    ) -> dict:
        """åˆ†æç”¨æˆ¶æ„åœ–"""
        pass

    @abstractmethod
    async def generate_follow_up_question(
        self, missing_info: list, current_context: dict, user_input: str
    ) -> str:
        """ç”Ÿæˆå¾ŒçºŒå•é¡Œ"""
        pass

    @abstractmethod
    async def generate_search_response(
        self,
        restaurants: list,
        user_preferences: dict,
        search_params: dict,
        user_input: str,
    ) -> dict:
        """ç”Ÿæˆæœå°‹çµæœå›æ‡‰"""
        pass


class GeminiAIService(AIServiceInterface):
    """Gemini AI æœå‹™"""

    def __init__(self, config: AISettings):
        self.config = config
        # é©—è­‰è¨­å®š
        self.config.validate()

        # åˆå§‹åŒ–å®¢æˆ¶ç«¯
        self.client = genai.Client(api_key=config.api_key)

        # åˆå§‹åŒ– Prompt å»ºæ§‹å™¨
        self.prompt_builder = SystemPromptBuilder()

        self.response_formatter = ResponseFormatter()

        logger.info(f"ğŸš€ Gemini AI æœå‹™åˆå§‹åŒ–å®Œæˆ - æ¨¡å‹: {config.model}")

    def _convert_messages_to_contents(
        self, messages: List[ChatMessage]
    ) -> List[Dict[str, Any]]:
        """è½‰æ›è¨Šæ¯æ ¼å¼çµ¦ Gemini API"""
        role_map = {
            MessageRole.SYSTEM: "model",  # ä½¿ç”¨å¸¸æ•¸
            MessageRole.ASSISTANT: "model",
            MessageRole.USER: "user",
        }

        contents = []
        for msg in messages:
            # è·³éç³»çµ±è¨Šæ¯ï¼Œå› ç‚ºæˆ‘å€‘æœƒç”¨ system_instruction
            if msg.role == MessageRole.SYSTEM:
                continue

            contents.append(
                {
                    "role": role_map.get(msg.role, "user"),
                    "parts": [{"text": msg.content}],
                }
            )

        return contents

    async def _call_gemini_api(
        self,
        prompt_type: PromptType,
        user_message: str,
        custom_prompt: Optional[str] = None,
        **prompt_kwargs,
    ) -> str:
        """çµ±ä¸€çš„ Gemini API èª¿ç”¨æ–¹æ³•"""
        try:
            # ä½¿ç”¨çµæ§‹åŒ– Prompt æˆ–è‡ªå®šç¾© Prompt
            if custom_prompt:
                system_prompt = custom_prompt
            else:
                system_prompt = self.prompt_builder.build_prompt(
                    prompt_type, **prompt_kwargs
                )

            contents = [{"role": "user", "parts": [{"text": user_message}]}]

            # æ ¹æ“š Prompt é¡å‹ä½¿ç”¨å°æ‡‰çš„é…ç½®
            temperature = PromptConfig.TEMPERATURES.get(
                prompt_type, self.config.temperature
            )
            max_tokens = PromptConfig.MAX_TOKENS.get(
                prompt_type, self.config.max_tokens
            )

            generation_config = types.GenerateContentConfig(
                system_instruction=system_prompt,
                temperature=temperature,
                max_output_tokens=max_tokens,
                top_p=self.config.top_p,
                top_k=self.config.top_k,
            )

            response = self.client.models.generate_content(
                model=self.config.model,
                config=generation_config,
                contents=contents,
            )

            if not response or not response.text:
                raise AIServiceError("AI å›æ‡‰ç‚ºç©º")

            logger.debug(f"ä½¿ç”¨ Prompt é¡å‹: {prompt_type.value}, æº«åº¦: {temperature}")

            return self.response_formatter.clean_ai_response(response.text.strip())

        except Exception as e:
            logger.error(f"âŒ Gemini API èª¿ç”¨å¤±æ•—: {e}")
            raise AIServiceError(f"AI æœå‹™ç•°å¸¸: {str(e)}")

    async def generate_response(self, messages: List[ChatMessage]) -> str:
        """ç”Ÿæˆä¸€èˆ¬å°è©± AI å›æ‡‰"""
        try:
            # è½‰æ›è¨Šæ¯æ ¼å¼
            contents = self._convert_messages_to_contents(messages)

            logger.info(f"ğŸ“¤ ç™¼é€è«‹æ±‚åˆ° Gemini API - è¨Šæ¯æ•¸: {len(contents)}")

            # å¯ä»¥é¸æ“‡ä½¿ç”¨åŸæœ‰çš„ SYSTEM_PROMPT æˆ–æ–°çš„çµæ§‹åŒ– Prompt
            # ç‚ºäº†å‘å¾Œå…¼å®¹ï¼Œé€™è£¡ä½¿ç”¨åŸæœ‰çš„ SYSTEM_PROMPT
            system_prompt = self.prompt_builder.get_legacy_prompt()

            # é…ç½®ç”Ÿæˆåƒæ•¸
            generation_config = types.GenerateContentConfig(
                system_instruction=system_prompt,
                temperature=self.config.temperature,
                max_output_tokens=self.config.max_tokens,
                top_p=self.config.top_p,
                top_k=self.config.top_k,
            )

            # èª¿ç”¨ API
            response = self.client.models.generate_content(
                model=self.config.model,
                config=generation_config,
                contents=contents,
            )
            print(f"{response.usage_metadata=}")

            if not response or not response.text:
                raise AIServiceError("AI å›æ‡‰ç‚ºç©º")

            response_text = response.text.strip()
            logger.info(f"ğŸ“¥ AI å›æ‡‰æˆåŠŸ - é•·åº¦: {len(response_text)} å­—ç¬¦")
            logger.debug(f"å›æ‡‰å…§å®¹é è¦½: {response_text[:100]}...")

            return response_text

        except Exception as e:
            logger.error(f"âŒ AI æœå‹™èª¿ç”¨å¤±æ•—: {type(e).__name__}: {e}")

            # æ›´è©³ç´°çš„éŒ¯èª¤è™•ç†
            if "API_KEY" in str(e).upper():
                raise AIServiceError("API Key ç„¡æ•ˆæˆ–æœªè¨­å®š")
            elif "QUOTA" in str(e).upper():
                raise AIServiceError("API é…é¡å·²ç”¨å®Œ")
            elif "MODEL" in str(e).upper():
                raise AIServiceError(f"æ¨¡å‹ '{self.config.model}' ä¸å¯ç”¨")
            else:
                raise AIServiceError(f"AI æœå‹™ç•°å¸¸: {str(e)}")

    async def analyze_user_intent(
        self, user_input: str, session_history: dict, context: dict
    ) -> dict:
        """åˆ†æç”¨æˆ¶æ„åœ–ä¸¦æå–é¤å»³æœå°‹åƒæ•¸"""
        try:
            user_message = f"""
            ç”¨æˆ¶è¼¸å…¥: "{user_input}"
            æœƒè©±æ­·å²: {json.dumps(session_history, ensure_ascii=False, indent=2)}
            ä¸Šä¸‹æ–‡: {json.dumps(context, ensure_ascii=False, indent=2)}

            è«‹åˆ†æé€™å€‹ç”¨æˆ¶è¼¸å…¥ä¸¦æå–é¤å»³æœå°‹ç›¸é—œä¿¡æ¯ã€‚
            """

            # æ·»åŠ é¡å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯åˆ° Prompt
            prompt_kwargs = {}
            if context.get("location"):
                prompt_kwargs["ç”¨æˆ¶ä½ç½®"] = context["location"]
            if context.get("time"):
                prompt_kwargs["ç•¶å‰æ™‚é–“"] = context["time"]

            response_text = await self._call_gemini_api(
                PromptType.INTENT_ANALYSIS, user_message, **prompt_kwargs
            )

            # å˜—è©¦è§£æ JSON å›æ‡‰
            try:
                result = json.loads(response_text)
                logger.info(
                    f"ğŸ§  AI æ„åœ–åˆ†ææˆåŠŸ - ä¿¡å¿ƒåº¦: {result.get('confidence', 0)}"
                )
                return result
            except json.JSONDecodeError:
                logger.error(f"AI å›æ‡‰ä¸æ˜¯æœ‰æ•ˆçš„ JSON: {response_text}")
                return {
                    "success": False,
                    "confidence": 0.0,
                    "extracted_info": {},
                    "missing_info": ["æ‰€æœ‰å¿…è¦ä¿¡æ¯"],
                    "user_intent": "ç„¡æ³•è§£æç”¨æˆ¶æ„åœ–",
                }

        except Exception as e:
            logger.error(f"âŒ ç”¨æˆ¶æ„åœ–åˆ†æå¤±æ•—: {e}")
            return {
                "success": False,
                "confidence": 0.0,
                "extracted_info": {},
                "missing_info": ["æ‰€æœ‰å¿…è¦ä¿¡æ¯"],
                "user_intent": "åˆ†æéç¨‹ä¸­å‡ºç¾éŒ¯èª¤",
            }

    async def generate_follow_up_question(
        self, missing_info: list, current_context: dict, user_input: str
    ) -> str:
        """ç”Ÿæˆå¾ŒçºŒå•é¡Œä¾†æ”¶é›†ç¼ºå°‘çš„ä¿¡æ¯"""
        try:
            user_message = f"""
ç”¨æˆ¶åŸå§‹è¼¸å…¥: "{user_input}"
ç›®å‰å·²æ”¶é›†çš„ä¿¡æ¯: {json.dumps(current_context, ensure_ascii=False, indent=2)}
ç¼ºå°‘çš„ä¿¡æ¯: {missing_info}

è«‹ç”Ÿæˆä¸€å€‹è‡ªç„¶çš„å•é¡Œä¾†æ”¶é›†æœ€é‡è¦çš„ç¼ºå°‘ä¿¡æ¯ã€‚
"""

            # æ ¹æ“šç¼ºå°‘çš„ä¿¡æ¯é¡å‹èª¿æ•´ Prompt
            prompt_kwargs = {}
            if "cuisine" in missing_info:
                prompt_kwargs["é‡é»"] = "å„ªå…ˆè©¢å•æ–™ç†é¡å‹åå¥½"
            elif "radius" in missing_info:
                prompt_kwargs["é‡é»"] = "å„ªå…ˆè©¢å•è·é›¢ç¯„åœ"
            elif "price_level" in missing_info:
                prompt_kwargs["é‡é»"] = "å„ªå…ˆè©¢å•åƒ¹ä½é ç®—"

            question = await self._call_gemini_api(
                PromptType.FOLLOW_UP_QUESTION, user_message, **prompt_kwargs
            )

            logger.info(f"ğŸ’­ ç”Ÿæˆå¾ŒçºŒå•é¡ŒæˆåŠŸ")
            return question

        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå¾ŒçºŒå•é¡Œå¤±æ•—: {e}")
            return "è«‹å‘Šè¨´æˆ‘æ‚¨æƒ³è¦ä»€éº¼é¡å‹çš„é¤å»³ï¼Ÿ"

    async def generate_search_response(
        self,
        restaurants: list,
        user_preferences: dict,
        search_params: dict,
        user_input: str,
    ) -> dict:
        """ç”Ÿæˆå€‹æ€§åŒ–çš„æœå°‹çµæœå›æ‡‰"""
        try:
            restaurant_summary = []
            for r in restaurants[:5]:  # åªå–å‰ 5 å€‹åšæ‘˜è¦
                restaurant_summary.append(
                    {
                        "name": getattr(r, "name", "æœªçŸ¥"),
                        "cuisine": getattr(r, "cuisine", "æœªçŸ¥"),
                        "rating": getattr(r, "rating", 0),
                        "price_level": getattr(r, "price_level", 0),
                        "distance_km": getattr(r, "distance_km", 0),
                    }
                )

            user_message = f"""
ç”¨æˆ¶åŸå§‹éœ€æ±‚: "{user_input}"
ç”¨æˆ¶åå¥½: {json.dumps(user_preferences, ensure_ascii=False, indent=2)}
æœå°‹åƒæ•¸: {json.dumps(search_params, ensure_ascii=False, indent=2)}
æ‰¾åˆ°çš„é¤å»³æ•¸é‡: {len(restaurants)}
é¤å»³æ‘˜è¦: {json.dumps(restaurant_summary, ensure_ascii=False, indent=2)}

è«‹ç”Ÿæˆå€‹æ€§åŒ–çš„å›æ‡‰è¨Šæ¯ã€‚
"""

            # æ ¹æ“šçµæœæ•¸é‡èª¿æ•´ Prompt
            prompt_kwargs = {}
            if len(restaurants) == 0:
                prompt_kwargs["æƒ…æ³"] = "æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„é¤å»³"
            elif len(restaurants) > 20:
                prompt_kwargs["æƒ…æ³"] = "æ‰¾åˆ°å¾ˆå¤šé¤å»³ï¼Œéœ€è¦å¹«åŠ©ç¯©é¸"
            elif len(restaurants) < 5:
                prompt_kwargs["æƒ…æ³"] = "é¤å»³é¸æ“‡è¼ƒå°‘"

            response_text = await self._call_gemini_api(
                PromptType.SEARCH_RESPONSE, user_message, **prompt_kwargs
            )

            try:
                result = json.loads(response_text)
                logger.info(f"ğŸ’¬ ç”Ÿæˆæœå°‹å›æ‡‰æˆåŠŸ")
                return result
            except json.JSONDecodeError:
                logger.error(f"æœå°‹å›æ‡‰ä¸æ˜¯æœ‰æ•ˆçš„ JSON: {response_text}")
                return {
                    "message": f"æˆ‘ç‚ºæ‚¨æ‰¾åˆ°äº† {len(restaurants)} å®¶ç¬¦åˆæ¢ä»¶çš„é¤å»³ï¼",
                    "highlights": ["æ ¹æ“šæ‚¨çš„åå¥½ç¯©é¸"],
                    "suggestions": ["æ‚¨å¯ä»¥æŸ¥çœ‹è©³ç´°ä¿¡æ¯é¸æ“‡æœ€å–œæ­¡çš„"],
                }

        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæœå°‹å›æ‡‰å¤±æ•—: {e}")
            return {
                "message": f"æˆ‘ç‚ºæ‚¨æ‰¾åˆ°äº† {len(restaurants)} å®¶é¤å»³ï¼",
                "highlights": [],
                "suggestions": [],
            }

    # === æ–°å¢çš„ä¾¿åˆ©æ–¹æ³• ===

    async def legacy_restaurant_search(self, messages: List[ChatMessage]) -> str:
        """ä½¿ç”¨åŸæœ‰é‚è¼¯çš„é¤å»³æœå°‹ï¼ˆå‘å¾Œå…¼å®¹ï¼‰"""
        try:
            contents = self._convert_messages_to_contents(messages)

            # ä½¿ç”¨åŸæœ‰çš„ Prompt é‚è¼¯
            response_text = await self._call_gemini_api(
                PromptType.LEGACY_RESTAURANT_SEARCH,
                contents[-1]["parts"][0]["text"] if contents else "",
            )

            logger.info(f"ğŸ”„ ä½¿ç”¨åŸæœ‰é¤å»³æœå°‹é‚è¼¯æˆåŠŸ")
            return response_text

        except Exception as e:
            logger.error(f"âŒ åŸæœ‰é¤å»³æœå°‹å¤±æ•—: {e}")
            raise AIServiceError(f"é¤å»³æœå°‹æœå‹™ç•°å¸¸: {str(e)}")

    def update_prompt_template(self, prompt_type: PromptType, **updates):
        """å‹•æ…‹æ›´æ–° Prompt æ¨¡æ¿ï¼ˆå¯ç”¨æ–¼ A/B æ¸¬è©¦æˆ–é…ç½®èª¿æ•´ï¼‰"""
        try:
            template = self.prompt_builder.templates.get(prompt_type)
            if template:
                for key, value in updates.items():
                    if hasattr(template, key):
                        setattr(template, key, value)
                logger.info(f"ğŸ“ æ›´æ–° Prompt æ¨¡æ¿: {prompt_type.value}")
            else:
                logger.warning(f"æœªæ‰¾åˆ° Prompt æ¨¡æ¿: {prompt_type.value}")
        except Exception as e:
            logger.error(f"âŒ æ›´æ–° Prompt æ¨¡æ¿å¤±æ•—: {e}")

    def get_prompt_preview(self, prompt_type: PromptType, **kwargs) -> str:
        """é è¦½ç”Ÿæˆçš„ Promptï¼ˆç”¨æ–¼èª¿è©¦ï¼‰"""
        try:
            return self.prompt_builder.build_prompt(prompt_type, **kwargs)
        except Exception as e:
            logger.error(f"âŒ é è¦½ Prompt å¤±æ•—: {e}")
            return f"ç„¡æ³•é è¦½ Prompt: {e}"

    def switch_to_advanced_mode(self, enable: bool = True):
        """åˆ‡æ›åˆ°é«˜ç´šæ¨¡å¼ï¼ˆä½¿ç”¨æ–°çš„çµæ§‹åŒ– Promptï¼‰"""
        if enable:
            logger.info("ğŸ”„ åˆ‡æ›åˆ°é«˜ç´š AI æ¨¡å¼")
            # å¯ä»¥åœ¨é€™è£¡æ·»åŠ åˆ‡æ›é‚è¼¯
        else:
            logger.info("ğŸ”„ åˆ‡æ›åˆ°å…¼å®¹æ¨¡å¼")
            # ä¿æŒåŸæœ‰é‚è¼¯
